{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn import metrics\n",
    "from MF import PureSingularValueDecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class RegularizedSingularValueDecomposition:\n",
    "    def __init__(self, records_train, records_test):\n",
    "        records = np.vstack([records_train, records_test])\n",
    "        self.n = len(np.unique(np.sort(records[:, 0])))\n",
    "        self.m = len(np.unique(np.sort(records[:, 1])))\n",
    "\n",
    "        # Initial R\n",
    "        self.R = np.zeros([self.n, self.m], dtype=np.int32)\n",
    "\n",
    "        for record in records_train:\n",
    "            self.R[record[0], record[1]] = record[2]\n",
    "\n",
    "        # Initial indicator\n",
    "        y = np.where(self.R, 1, 0)\n",
    "        y_user = np.sum(y, axis=1)\n",
    "        y_item = np.sum(y, axis=0)\n",
    "\n",
    "        # Global average of rating\n",
    "        self.r = np.sum(self.R) / np.sum(y)\n",
    "\n",
    "        # average rating of user\n",
    "        self.r_u = np.where(y_user,\n",
    "                            np.sum(self.R, axis=1) / y_user,\n",
    "                            self.r)\n",
    "\n",
    "        # average rating of item\n",
    "        self.r_i = np.where(y_item,\n",
    "                            np.sum(self.R, axis=0) / y_item,\n",
    "                            self.r)\n",
    "\n",
    "        # bias of user\n",
    "        self.b_u = np.where(y_user,\n",
    "                            np.sum(y * (self.R - self.r_i), axis=1) / y_user,\n",
    "                            0)\n",
    "\n",
    "        # bias of item\n",
    "        self.b_i = np.where(y_item,\n",
    "                            np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
    "                            0)\n",
    "        \n",
    "    def gradient_descent(self, n_iter=5):\n",
    "\n",
    "        alpha = 0.01\n",
    "        d = 20\n",
    "        \n",
    "        # Initialize\n",
    "        U = (np.random.randint(0, 1, size=(self.n, d)) - 0.5) * 0.01\n",
    "        V = (np.random.randint(0, 1, size=(self.m, d)) - 0.5) * 0.01\n",
    "        mu = self.r\n",
    "        b_i = self.b_i\n",
    "        b_u = self.b_u\n",
    "        \n",
    "        eta = 0.05\n",
    "        \n",
    "        def dJ_sgd(mu, b_u, b_i, U, V, r):\n",
    "            e = r - (mu + b_u + b_i + U.dot(V))\n",
    "            return -e, -e + alpha * b_u, -e + alpha * b_i, -e * V + alpha * U, -e * U + alpha * V\n",
    "        \n",
    "        for cur_iter in range(n_iter):\n",
    "            if cur_iter > -1:\n",
    "                # print(cur_iter)\n",
    "                f.write(f\"{cur_iter}\\n\")\n",
    "            ratings = np.where(self.R != 0)\n",
    "            num = len(ratings[0])\n",
    "            indexes = np.random.permutation(num)\n",
    "            users = ratings[0][indexes]\n",
    "            items = ratings[1][indexes]\n",
    "\n",
    "            for i in range(num):\n",
    "                user = users[i]\n",
    "                item = items[i]\n",
    "                gradient_mu, gradient_b_u, gradient_b_i, gradient_U, gradient_V = dJ_sgd(mu, b_u[user], b_i[item], U[user, :], V[item, :], self.R[user, item])\n",
    "                mu -= eta * gradient_mu\n",
    "                b_u[user] -= eta * gradient_b_u\n",
    "                b_i[item] -= eta * gradient_b_i\n",
    "                U[user, :] -= eta * gradient_U\n",
    "                V[item, :] -= eta * gradient_V\n",
    "                \n",
    "                # b_u -= eta * gradient_b_u\n",
    "                # b_i -= eta * gradient_b_i\n",
    "                # U -= eta * gradient_U\n",
    "                # V -= eta * gradient_V\n",
    "                \n",
    "            eta = eta * 0.9\n",
    "            ratings_predict_rsvd = performance(mu, b_u, b_i, U, V, records_test)\n",
    "            if cur_iter > -1:\n",
    "                print(score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test))\n",
    "                # print(score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test))\n",
    "                f.write(f\"{score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test)}\\n\")\n",
    "        print(\"RSVD FINISHED\")\n",
    "        return mu, b_u, b_i, U, V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class Nomu:\n",
    "    def __init__(self, records_train, records_test):\n",
    "        records = np.vstack([records_train, records_test])\n",
    "        self.n = len(np.unique(np.sort(records[:, 0])))\n",
    "        self.m = len(np.unique(np.sort(records[:, 1])))\n",
    "\n",
    "        # Initial R\n",
    "        self.R = np.zeros([self.n, self.m], dtype=np.int32)\n",
    "\n",
    "        for record in records_train:\n",
    "            self.R[record[0], record[1]] = record[2]\n",
    "\n",
    "        # Initial indicator\n",
    "        y = np.where(self.R, 1, 0)\n",
    "        y_user = np.sum(y, axis=1)\n",
    "        y_item = np.sum(y, axis=0)\n",
    "\n",
    "        # Global average of rating\n",
    "        self.r = np.sum(self.R) / np.sum(y)\n",
    "\n",
    "        # average rating of user\n",
    "        self.r_u = np.where(y_user,\n",
    "                            np.sum(self.R, axis=1) / y_user,\n",
    "                            self.r)\n",
    "\n",
    "        # average rating of item\n",
    "        self.r_i = np.where(y_item,\n",
    "                            np.sum(self.R, axis=0) / y_item,\n",
    "                            self.r)\n",
    "\n",
    "        # bias of user\n",
    "        self.b_u = np.where(y_user,\n",
    "                            np.sum(y * (self.R - self.r_i), axis=1) / y_user,\n",
    "                            0)\n",
    "\n",
    "        # bias of item\n",
    "        self.b_i = np.where(y_item,\n",
    "                            np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
    "                            0)\n",
    "        \n",
    "    def gradient_descent(self, n_iter=5):\n",
    "        # print(\"NOMU\")\n",
    "        f.write(\"NOMU\")\n",
    "        alpha = 0.01\n",
    "        d = 20\n",
    "        \n",
    "        # Initialize\n",
    "        U = (np.random.randint(0, 1, size=(self.n, d)) - 0.5) * 0.01\n",
    "        V = (np.random.randint(0, 1, size=(self.m, d)) - 0.5) * 0.01\n",
    "        mu = self.r\n",
    "        b_i = self.b_i\n",
    "        b_u = self.b_u\n",
    "        \n",
    "        eta = 0.05\n",
    "        \n",
    "        def dJ_sgd(mu, b_u, b_i, U, V, r):\n",
    "            e = r - (mu + b_u + b_i + U.dot(V))\n",
    "            return -e, -e + alpha * b_u, -e + alpha * b_i, -e * V + alpha * U, -e * U + alpha * V\n",
    "        \n",
    "        for cur_iter in range(n_iter):\n",
    "            if cur_iter > -1:\n",
    "                # print(cur_iter)\n",
    "                f.write(f\"{cur_iter}\\n\")\n",
    "            ratings = np.where(self.R != 0)\n",
    "            num = len(ratings[0])\n",
    "            indexes = np.random.permutation(num)\n",
    "            users = ratings[0][indexes]\n",
    "            items = ratings[1][indexes]\n",
    "\n",
    "            for i in range(num):\n",
    "                user = users[i]\n",
    "                item = items[i]\n",
    "                gradient_mu, gradient_b_u, gradient_b_i, gradient_U, gradient_V = dJ_sgd(mu, b_u[user], b_i[item], U[user, :], V[item, :], self.R[user, item])\n",
    "                # mu -= eta * gradient_mu\n",
    "                b_u[user] -= eta * gradient_b_u\n",
    "                b_i[item] -= eta * gradient_b_i\n",
    "                U[user, :] -= eta * gradient_U\n",
    "                V[item, :] -= eta * gradient_V\n",
    "                \n",
    "                # b_u -= eta * gradient_b_u\n",
    "                # b_i -= eta * gradient_b_i\n",
    "                # U -= eta * gradient_U\n",
    "                # V -= eta * gradient_V\n",
    "                \n",
    "            eta = eta * 0.9\n",
    "            ratings_predict_rsvd = performance(mu, b_u, b_i, U, V, records_test)\n",
    "            if cur_iter > -1:\n",
    "                print(score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test))\n",
    "                f.write(f\"{score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test)}\\n\")\n",
    "\n",
    "        return mu, b_u, b_i, U, V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class Nobi:\n",
    "    def __init__(self, records_train, records_test):\n",
    "        records = np.vstack([records_train, records_test])\n",
    "        self.n = len(np.unique(np.sort(records[:, 0])))\n",
    "        self.m = len(np.unique(np.sort(records[:, 1])))\n",
    "\n",
    "        # Initial R\n",
    "        self.R = np.zeros([self.n, self.m], dtype=np.int32)\n",
    "\n",
    "        for record in records_train:\n",
    "            self.R[record[0], record[1]] = record[2]\n",
    "\n",
    "        # Initial indicator\n",
    "        y = np.where(self.R, 1, 0)\n",
    "        y_user = np.sum(y, axis=1)\n",
    "        y_item = np.sum(y, axis=0)\n",
    "\n",
    "        # Global average of rating\n",
    "        self.r = np.sum(self.R) / np.sum(y)\n",
    "\n",
    "        # average rating of user\n",
    "        self.r_u = np.where(y_user,\n",
    "                            np.sum(self.R, axis=1) / y_user,\n",
    "                            self.r)\n",
    "\n",
    "        # average rating of item\n",
    "        self.r_i = np.where(y_item,\n",
    "                            np.sum(self.R, axis=0) / y_item,\n",
    "                            self.r)\n",
    "\n",
    "        # bias of user\n",
    "        self.b_u = np.where(y_user,\n",
    "                            np.sum(y * (self.R - self.r_i), axis=1) / y_user,\n",
    "                            0)\n",
    "\n",
    "        # bias of item\n",
    "        self.b_i = np.where(y_item,\n",
    "                            np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
    "                            0)\n",
    "\n",
    "    def gradient_descent(self, n_iter=5):\n",
    "        f.write(\"NOBI\\n\")\n",
    "        alpha = 0.01\n",
    "        d = 20\n",
    "\n",
    "        # Initialize\n",
    "        U = (np.random.randint(0, 1, size=(self.n, d)) - 0.5) * 0.01\n",
    "        V = (np.random.randint(0, 1, size=(self.m, d)) - 0.5) * 0.01\n",
    "        mu = self.r\n",
    "        b_i = self.b_i\n",
    "        b_u = self.b_u\n",
    "\n",
    "        eta = 0.05\n",
    "\n",
    "        def dJ_sgd(mu, b_u, b_i, U, V, r):\n",
    "            e = r - (mu + b_u + b_i + U.dot(V))\n",
    "            return -e, -e + alpha * b_u, -e + alpha * b_i, -e * V + alpha * U, -e * U + alpha * V\n",
    "\n",
    "        def get_eta(t):\n",
    "            return 1 / (t + 11)\n",
    "\n",
    "\n",
    "        for cur_iter in range(n_iter):\n",
    "            if cur_iter > -1:\n",
    "                # print(cur_iter)\n",
    "                f.write(f\"{cur_iter}\\n\")\n",
    "            ratings = np.where(self.R != 0)\n",
    "            num = len(ratings[0])\n",
    "            indexes = np.random.permutation(num)\n",
    "            users = ratings[0][indexes]\n",
    "            items = ratings[1][indexes]\n",
    "\n",
    "            for i in range(num):\n",
    "                user = users[i]\n",
    "                item = items[i]\n",
    "                gradient_mu, gradient_b_u, gradient_b_i, gradient_U, gradient_V = dJ_sgd(mu, b_u[user], b_i[item], U[user, :], V[item, :], self.R[user, item])\n",
    "                # mu -= eta * gradient_mu\n",
    "                # b_u[user] -= eta * gradient_b_u\n",
    "                # b_i[item] -= eta * gradient_b_i\n",
    "                # eta = get_eta(cur_iter * num)\n",
    "                U[user, :] -= eta * gradient_U\n",
    "                V[item, :] -= eta * gradient_V\n",
    "\n",
    "                # b_u -= eta * gradient_b_u\n",
    "                # b_i -= eta * gradient_b_i\n",
    "                # U -= eta * gradient_U\n",
    "                # V -= eta * gradient_V\n",
    "\n",
    "            eta = eta * 0.95\n",
    "            ratings_predict_rsvd = performance(mu, b_u, b_i, U, V, records_test)\n",
    "            if cur_iter > -1:\n",
    "                print(score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test))\n",
    "                f.write(f\"{score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test)}\\n\")\n",
    "\n",
    "        return mu, b_u, b_i, U, V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, records_train, records_test):\n",
    "        records = np.vstack([records_train, records_test])\n",
    "        self.n = len(np.unique(np.sort(records[:, 0])))\n",
    "        self.m = len(np.unique(np.sort(records[:, 1])))\n",
    "\n",
    "        # Initial R\n",
    "        self.R = np.zeros([self.n, self.m], dtype=np.int32)\n",
    "\n",
    "        for record in records_train:\n",
    "            self.R[record[0], record[1]] = record[2]\n",
    "\n",
    "        # Initial indicator\n",
    "        y = np.where(self.R, 1, 0)\n",
    "        y_user = np.sum(y, axis=1)\n",
    "        y_item = np.sum(y, axis=0)\n",
    "\n",
    "        # Global average of rating\n",
    "        self.r = np.sum(self.R) / np.sum(y)\n",
    "\n",
    "        # average rating of user\n",
    "        self.r_u = np.where(y_user,\n",
    "                            np.sum(self.R, axis=1) / y_user,\n",
    "                            self.r)\n",
    "\n",
    "        # average rating of item\n",
    "        self.r_i = np.where(y_item,\n",
    "                            np.sum(self.R, axis=0) / y_item,\n",
    "                            self.r)\n",
    "\n",
    "        # bias of user\n",
    "        self.b_u = np.where(y_user,\n",
    "                            np.sum(y * (self.R - self.r_i), axis=1) / y_user,\n",
    "                            0)\n",
    "\n",
    "        # bias of item\n",
    "        self.b_i = np.where(y_item,\n",
    "                            np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
    "                            0)\n",
    "        \n",
    "    def gradient_descent(self, n_iter=5000):\n",
    "\n",
    "\n",
    "        R_svd = np.where(self.R == 0,\n",
    "                          np.zeros(shape=self.R.shape) + self.r_u.reshape(-1, 1),\n",
    "                          self.R)\n",
    "        # SVD\n",
    "        U, s, VT = svd(R_svd)\n",
    "\n",
    "        d = 20\n",
    "        Sigma = np.zeros([d, d])\n",
    "        for i in range(d):\n",
    "            Sigma[i][i] = s[i]\n",
    "        \n",
    "        U = U[:, :d].dot(Sigma)\n",
    "        V = VT[:d, :].T\n",
    "        \n",
    "        def performance():\n",
    "            return U.dot(V.T)[records_test[:, 0], records_test[:, 1]]\n",
    "        ratings_predict_rsvd = performance()\n",
    "        print(score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test))\n",
    "        print(\"GG\")\n",
    "        eta = 0.0001\n",
    "        alpha = 0.0001\n",
    "        mu = self.r\n",
    "        \n",
    "        def dJ_sgd(U, V, r):\n",
    "            e = r - U.dot(V)\n",
    "            return -e * V + alpha * U, -e * U + alpha * V\n",
    "\n",
    "        for cur_iter in range(n_iter):\n",
    "            print(cur_iter)\n",
    "            ratings = np.where(self.R != 0)\n",
    "            num = len(ratings[0])\n",
    "            indexes = np.random.permutation(num)\n",
    "            users = ratings[0][indexes]\n",
    "            items = ratings[1][indexes]\n",
    "            \n",
    "            for i in range(num):\n",
    "                user = users[i]\n",
    "                item = items[i]\n",
    "                gradient_U, gradient_V = dJ_sgd(U[user, :], V[item, :], self.R[user, item])\n",
    "                \n",
    "                U[user, :] -= eta * gradient_U\n",
    "                V[item, :] -= eta * gradient_V\n",
    "                ratings_predict_rsvd = performance()\n",
    "                if not ratings_predict_rsvd.min() > -10:\n",
    "                    print(i)\n",
    "                    break\n",
    "                # U -= eta * gradient_U\n",
    "                # V -= eta * gradient_V\n",
    "                \n",
    "            eta = eta * 0.9\n",
    "            ratings_predict_rsvd = performance()\n",
    "            # print(ratings_predict_rsvd.min() > -10)\n",
    "            # print(ratings_predict_rsvd[:20])\n",
    "            print(score(np.clip(ratings_predict_rsvd, 1, 5), ratings_test))\n",
    "\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def score(ratings_test, ratings_predict):\n",
    "    return [round(sqrt(metrics.mean_squared_error(ratings_test, ratings_predict)), 4),\n",
    "            round(metrics.mean_absolute_error(ratings_test, ratings_predict), 4)]\n",
    "def performance(mu, b_u, b_i, U, V, records_test):\n",
    "        return mu + b_u[records_test[:, 0]] + b_i[records_test[:, 1]] + U.dot(V.T)[records_test[:, 0], records_test[:, 1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load the records\n",
    "records_train = np.loadtxt('../data/ml-100k/u1.base', dtype=np.int32)\n",
    "records_test = np.loadtxt('../data/ml-100k/u1.test', dtype=np.int32)\n",
    "\n",
    "# Preprocess\n",
    "records_train[:, :2] -= 1\n",
    "records_test[:, :2] -= 1\n",
    "ratings_test = records_test[:, 2]\n",
    "records = np.vstack([records_train, records_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\recommender-algorithm-implementation\\Matrix Factorization\\MF.py:39: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 569 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "psvd = PureSingularValueDecomposition(records_train, records_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.017, 0.8058]\n"
     ]
    }
   ],
   "source": [
    "ratings_predict = psvd.performance(records_test)\n",
    "# ratings_predict.max()\n",
    "\n",
    "print(score(np.clip(ratings_predict, 1, 5), ratings_test))\n",
    "# score(np.clip(ratings_predict, 1, 5), ratings_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-e93682ee952f>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-31-e93682ee952f>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
      "<ipython-input-37-16130be8d572>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-37-16130be8d572>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
      "<ipython-input-33-8e2daa1e15ed>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-33-8e2daa1e15ed>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSVD FINISHED\n",
      "Wall time: 5min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": "(3.52835,\n array([ 1.08952097e-01,  1.47292722e-01, -2.96089856e-01,  9.95861591e-01,\n        -3.07979273e-01, -2.13216449e-01,  4.17613261e-01,  1.55244582e-01,\n         4.37816226e-01,  3.93208874e-01, -3.14850500e-02,  4.85574031e-01,\n        -2.04277013e-01,  4.53709133e-01, -3.78670265e-01,  6.83629005e-01,\n        -4.51756604e-01,  1.90466363e-01,  5.30517075e-02, -3.50328603e-01,\n        -2.61375162e-01, -3.90854408e-02, -3.90906427e-02,  6.23449095e-01,\n         1.82629893e-01, -4.87171487e-01, -1.25888340e-01,  1.63794270e-01,\n         1.57708335e-01,  3.20418408e-01,  2.39244734e-01, -8.13165066e-02,\n         4.79262630e-01,  6.12226446e-01, -1.30150467e-01,  1.10085655e+00,\n         5.97272814e-02,  7.70034649e-01,  2.41236551e-01, -7.36980243e-01,\n        -1.66686506e-02,  9.72784422e-02,  1.66324018e-01, -3.15177347e-02,\n         2.12575771e-01,  5.27085214e-01,  1.55333386e-01, -1.60959765e-01,\n        -6.48810133e-01,  2.84395930e-02, -2.56067081e-01,  6.52560734e-01,\n         4.43804238e-01, -6.14301138e-02, -1.06471763e-02,  2.39594959e-01,\n         2.15327741e-01,  1.22340407e-01,  3.74960072e-01,  3.39723636e-01,\n        -6.44167485e-01, -2.53819709e-01, -5.28887546e-01, -1.21915012e-01,\n         2.72587466e-01, -1.85070084e-02,  3.63927478e-01, -3.25517510e-01,\n         5.98077898e-02, -7.88681541e-02, -9.20306986e-02,  1.11862219e-01,\n        -6.78092272e-02,  2.63621149e-01, -1.36216825e-01, -1.80176333e-01,\n        -3.61640462e-01,  7.05687664e-02,  4.74945250e-01,  6.15796218e-02,\n         1.17260840e-01, -3.83640809e-01,  3.82059049e-02,  1.93253391e-01,\n        -1.65021552e-01,  3.09494012e-01,  4.48793268e-01,  5.46525837e-01,\n         5.81628870e-01,  4.71344690e-01,  4.87761063e-02, -8.63873152e-02,\n        -5.15140388e-01,  2.06754083e-01, -5.51854887e-03,  2.66544229e-01,\n         1.40073613e-02,  2.16092856e-01,  2.40406447e-01, -3.29681387e-01,\n        -1.98820491e-01, -8.33108363e-01, -1.24719301e-01, -6.71686700e-01,\n        -1.51391671e-01,  5.05008458e-02, -5.70067236e-01, -3.54022367e-03,\n         1.49491332e-01, -1.47137142e-01, -1.63535027e-01,  4.20985098e-01,\n         3.60278853e-01, -3.47964607e-01,  3.05095088e-01, -4.36325225e-01,\n         3.67008407e-01,  1.02699216e+00,  3.98964654e-01, -1.41343222e-01,\n        -8.62959990e-02,  2.22596503e-01,  4.66528114e-02, -4.89816226e-01,\n         7.23731834e-02,  2.91306111e-01,  7.19511403e-01, -3.90204960e-02,\n        -5.95574890e-01,  7.91526290e-01,  2.35838800e-01, -2.11013139e-01,\n        -2.04298018e-01,  3.94986349e-02,  5.83783084e-02,  6.72085936e-01,\n         7.36056617e-01,  4.02867059e-01,  3.02866587e-01,  2.71238812e-01,\n         2.07203628e-01,  1.17192281e-01,  2.30876737e-01, -2.49740413e-02,\n         1.12192335e-01,  1.42031991e-01,  6.48447805e-01,  7.69472751e-02,\n        -4.82188637e-01,  2.42767832e-01,  3.50487983e-01,  8.74539298e-01,\n        -7.12443549e-01,  6.20002178e-02, -7.64387433e-01, -1.40071080e-01,\n         2.73464014e-01,  3.21137121e-01,  2.63074038e-01,  4.10989897e-01,\n        -1.22769729e+00, -1.47636039e-01, -6.84165000e-01,  7.00595808e-01,\n         1.40515449e-01,  1.04005409e-01,  2.62463433e-01, -4.57395541e-02,\n         1.79388547e-01,  5.86970738e-01, -2.37537238e-01, -7.79077402e-01,\n         8.13893345e-01,  4.30859276e-01, -3.68402244e-02,  1.36498645e-01,\n        -5.23904780e-03,  1.99390693e-01, -3.66174302e-01,  2.78610903e-01,\n        -1.35785360e+00,  2.22728088e-01, -2.50705667e-01,  5.55013039e-02,\n         1.14508927e-01,  5.72346639e-02,  3.51906294e-01,  2.64440838e-01,\n         2.11484478e-01, -2.38214647e-02,  3.82454605e-01, -6.37159351e-02,\n        -1.56650659e-01, -5.54409948e-01, -9.06532402e-02, -3.09896450e-01,\n        -2.23363541e-01, -3.78449383e-01, -3.07686788e-01,  5.97323198e-01,\n        -3.68922836e-01, -1.11033442e+00, -1.42796762e-01, -2.67772747e-02,\n        -6.04870081e-01, -1.30459129e+00, -3.67796152e-01,  2.56484745e-01,\n        -3.32631624e-01,  3.18055459e-01, -1.56713769e-01,  2.90350160e-01,\n         5.60303964e-01, -1.70859128e-02,  6.33873332e-02,  2.63329605e-01,\n        -3.45164840e-01, -1.84211818e-01,  5.55080441e-01,  3.78604293e-01,\n         1.73807658e-01, -2.43964929e-01, -1.68965559e-02, -2.99518956e-01,\n         7.99264312e-01, -1.89084236e-01, -1.65960996e-01, -7.91467171e-01,\n        -4.79654480e-01,  2.51005095e-01, -3.46905862e-02,  5.53532982e-02,\n         4.99804587e-01, -4.96897117e-01,  6.94035631e-02, -4.13344624e-01,\n         9.17599526e-03, -1.39295379e-01,  2.29251119e-01,  2.04595622e-01,\n        -7.12718670e-02,  7.38731800e-01, -7.73450673e-02,  2.06679260e-01,\n         1.07077353e-01, -3.75664440e-01,  9.66796293e-02, -6.77550267e-01,\n         4.62221046e-01,  3.09533981e-01,  1.14445388e-01,  9.44228498e-01,\n         2.03952896e-01, -1.83624820e-01, -6.32865560e-01,  7.21954716e-01,\n         5.23371522e-01,  2.23364301e-01,  2.20475144e-01,  7.75744595e-01,\n         9.39048219e-01, -3.16523833e-01,  2.32102483e-01,  5.49856419e-01,\n         2.24283668e-01, -3.61075106e-01,  4.93730610e-01, -3.76735092e-01,\n        -6.79867958e-01,  8.24895570e-01, -1.25102584e-01,  4.20400553e-01,\n        -2.38144438e-01,  5.23791687e-01, -5.22281855e-01,  1.18949757e-01,\n        -2.79505220e-01,  4.00786866e-01, -5.88541244e-02,  2.82508859e-01,\n         2.44470673e-02,  1.61870820e-01,  5.72357421e-01,  1.64182321e-01,\n        -1.01755343e-01,  4.32697764e-01,  2.91919598e-01, -7.16940330e-02,\n        -7.09733096e-01, -1.37559369e-01,  4.06697581e-01,  3.67420460e-01,\n        -4.47737345e-01,  2.60890925e-01,  7.03103459e-01,  4.46225332e-01,\n        -2.58764280e-01,  3.86246846e-01, -1.56593623e-01,  7.95749846e-01,\n         1.68677192e-01, -4.35766177e-01,  4.10338928e-02,  9.68135136e-02,\n        -3.31453720e-01, -2.00718543e-01, -1.39165668e-02,  2.07851451e-01,\n         4.57319659e-01, -6.75237335e-01,  1.66368280e-01,  5.92217444e-01,\n         1.01438985e-02,  4.07368272e-01,  2.64076289e-01, -7.29592582e-01,\n         5.08039987e-01,  1.56576813e-01, -1.11149825e-01,  4.73098475e-01,\n        -1.04876037e-01,  2.52196649e-01,  4.56320985e-02,  9.84191735e-01,\n        -2.61919596e-01, -5.06270943e-01, -3.46163233e-01, -7.73813333e-02,\n        -4.49255853e-01,  8.43920909e-01, -9.31922621e-02,  8.20319903e-01,\n        -1.47590145e-01, -7.77245347e-02,  1.79242934e-01, -1.76999985e-01,\n         4.78899274e-01,  2.13519793e-01,  4.20002214e-01,  3.34253252e-01,\n         7.57425214e-01, -1.60641237e-01,  3.59887970e-01,  1.38627201e-02,\n         1.27526933e-01, -9.08146945e-02,  1.61853489e-01,  6.56859576e-01,\n         9.50127015e-03,  3.50747936e-01,  8.28985948e-01, -1.00235076e-01,\n        -2.10851982e-01, -5.82533994e-02,  9.66353429e-01, -7.48614719e-02,\n         8.72253358e-01, -5.04325545e-02,  6.02275923e-01,  1.40210605e-01,\n        -1.97864532e-02,  3.92173284e-02, -4.03181721e-01,  3.46253178e-01,\n        -3.48688824e-02,  1.06787858e+00,  8.03641085e-01, -5.97969555e-02,\n         4.40590272e-01, -2.14438154e-01,  2.86412431e-01,  8.34552209e-01,\n         1.40278329e-01, -4.53498054e-02,  3.59951330e-01, -1.89124609e-01,\n         4.36710428e-01, -3.89785875e-02,  3.53151285e-01, -5.76238577e-01,\n         2.11123099e-01, -1.95236453e-01,  4.46260227e-01,  6.90428910e-01,\n        -3.39222038e-01,  4.41176190e-01, -2.65249496e-01,  7.72888125e-01,\n         7.93628736e-02,  9.43128553e-02, -4.86335543e-02,  3.29744518e-01,\n         7.22495692e-02,  4.01808810e-01,  2.40839333e-01,  8.44366053e-02,\n         1.43664093e-01, -8.33530949e-02, -4.18851846e-01,  1.72151478e-01,\n        -5.87067618e-01,  1.12902365e-01,  2.23733124e-01, -3.62437387e-02,\n        -1.22184180e+00, -1.63163893e-01, -1.09177423e-01,  2.84444994e-01,\n        -4.79079474e-02, -3.81128139e-01,  9.67061150e-03,  8.57872735e-02,\n         6.51681807e-02,  4.95161241e-01,  4.50299543e-01,  4.46935702e-01,\n        -7.71263685e-02, -7.47329145e-01,  1.93319755e-01,  3.34603773e-01,\n        -3.73440408e-02,  3.45918093e-02,  7.57734391e-02, -1.56052082e-01,\n        -4.40870567e-01, -9.90038293e-02,  1.36686984e+00,  6.40400655e-01,\n        -1.36319908e-01, -2.30259809e-01, -3.47551148e-02,  1.83075443e-01,\n        -1.21451709e-01,  4.49963271e-01, -4.94841755e-02,  3.18640663e-01,\n        -5.69918531e-02,  6.26791549e-01,  1.38595743e-01,  5.82540490e-01,\n         5.11221214e-02, -2.69263855e-01,  8.31649247e-02,  5.45028380e-02,\n        -1.41637059e+00, -6.30519722e-01,  3.16144661e-02, -1.62498594e-01,\n         2.11242753e-01,  3.72950137e-01, -2.81393665e-01, -2.57957697e-01,\n        -1.42887392e-01, -7.30517470e-01, -1.06869981e-01, -7.86144241e-02,\n         5.50434043e-01, -5.22228653e-02,  2.60331592e-02, -1.85573426e-01,\n        -4.65643291e-01,  5.41759224e-01, -5.05818037e-01,  5.03229672e-01,\n        -4.64321643e-01, -1.16164964e-01,  4.73534560e-02,  2.72538015e-01,\n         5.69128945e-01, -9.46791597e-03, -9.17273202e-02,  9.60757818e-01,\n         1.43234003e-01,  3.24105574e-01, -1.56306523e-01,  5.84000586e-02,\n         1.12228009e+00, -1.43882280e-01, -1.86393800e-01, -2.47628358e-01,\n         1.67197826e-01,  9.01826439e-04, -5.77158160e-01,  4.34854578e-01,\n        -4.29538084e-01, -1.54959576e-01,  1.80236714e-01, -4.03821118e-01,\n         6.05555799e-01, -7.44006584e-01,  4.38311930e-02, -4.35205743e-01,\n         1.43703568e-01,  9.51179725e-02,  5.30321089e-01, -5.45722490e-01,\n        -1.28580165e-01, -4.55006815e-01,  1.72772960e-02, -1.30313393e-01,\n         3.85324591e-01,  1.44435249e-01,  2.91739867e-01,  2.38839294e-01,\n        -2.96511396e-01,  1.31449717e-01,  1.38247795e+00,  4.30896268e-02,\n        -8.27328420e-01, -2.63442521e-01,  6.13794613e-01,  4.77710869e-01,\n         8.35664125e-01,  1.12453366e-01, -3.29216916e-01,  2.05387740e-01,\n        -1.03837711e-01,  3.43784367e-01,  9.78170955e-01,  3.47070270e-02,\n        -4.43025402e-01,  3.20137188e-01,  7.53274603e-01, -1.34225655e-01,\n        -1.33738241e-01, -3.21188898e-01, -4.63472050e-02,  5.69587879e-02,\n         3.75771251e-01,  1.15700032e-01,  1.87135821e-01,  7.38606901e-01,\n        -1.84100854e-01,  8.96414943e-01,  1.34898765e-01,  2.31233104e-01,\n        -7.18070994e-01, -2.22855607e-01,  1.56426824e-01,  2.09805230e-01,\n         2.37668403e-01, -1.06430024e-01, -1.12835468e-01, -5.42888147e-01,\n         9.94711772e-02,  6.67894943e-01,  1.08182970e-01,  2.11719905e-01,\n         2.53109895e-01,  3.58066209e-01,  3.94524939e-01, -2.11135763e-01,\n         2.22361378e-01,  1.15979583e-02,  4.36708567e-01,  3.76067595e-01,\n         2.15641537e-01,  4.05472206e-01, -1.34544632e-01, -1.63957421e-01,\n        -5.74268032e-01, -1.99292881e-01,  4.49595308e-01, -2.07902445e-02,\n         7.83374386e-01, -1.68321407e-01,  5.20100042e-02, -5.48311701e-01,\n         1.28668472e-02, -6.52769005e-01, -5.85386700e-01, -2.64781435e-01,\n        -1.94989833e-01, -3.69633444e-02, -8.02298301e-01, -1.07307868e-01,\n         3.49144698e-01, -7.78488416e-01, -2.25141573e-01,  2.28236193e-01,\n         1.88980345e-01, -8.54495367e-02,  5.37589423e-01, -2.09410974e-03,\n         4.61983049e-02, -5.30309573e-02, -1.97399794e-01,  2.68506106e-01,\n         1.90318945e-01, -5.70605005e-02, -3.27101518e-02,  3.11231435e-01,\n         3.39648427e-02, -3.45573155e-01, -3.03066876e-02,  1.38001305e-01,\n         2.87220748e-01,  3.16135552e-01,  7.14950892e-01,  2.24867082e-01,\n        -5.03646951e-01,  5.34214903e-01,  1.56447095e-01, -1.98136522e-01,\n         9.62113315e-02,  3.82730032e-01, -5.33170387e-02, -9.22657594e-02,\n        -7.37549949e-01, -9.91912966e-02,  3.50591628e-01, -1.31654397e-01,\n         4.09723274e-01, -2.18565613e-01,  1.56002429e-01,  2.21648399e-01,\n        -8.12447992e-01, -3.54334282e-01,  6.68805838e-02,  5.75094937e-01,\n         2.87729179e-01, -2.79411046e-02, -5.06698194e-02,  1.44990987e-01,\n        -3.53928312e-01, -8.70151591e-01, -2.58175741e-01,  1.22282978e+00,\n         3.85265398e-01, -6.26395805e-02, -2.17235147e-01, -6.64291271e-02,\n        -2.80060371e-01,  2.09774907e-03, -1.04191368e-01,  8.28780965e-01,\n        -8.66963334e-01, -1.48544338e-01, -7.87191020e-01,  6.89613022e-01,\n         1.99680183e-01,  4.41289431e-01,  1.18964558e-01,  7.60014147e-01,\n         1.71912426e-01, -3.42098354e-01,  2.32592339e-01, -6.26966046e-02,\n         3.11550639e-01, -3.93819896e-01, -3.22409008e-01, -2.69470421e-01,\n        -7.42834114e-01,  7.03963641e-02, -5.52071710e-01, -9.82105818e-01,\n        -3.41241741e-01, -8.10267023e-02,  4.63135607e-02, -8.36440249e-01,\n         1.21363704e-01,  3.08247846e-01,  5.36943737e-02, -8.79430997e-03,\n        -7.74468905e-02, -7.22607060e-02,  2.12903470e-02,  1.54580098e-02,\n        -4.64222911e-01, -5.29818680e-02,  1.49575788e-01, -1.59245665e-01,\n         2.32968593e-01,  2.08956626e-01,  3.65606437e-03,  6.98150511e-02,\n         3.21185533e-01, -3.28480247e-01, -1.10982418e-01,  2.30094225e-01,\n         1.12980034e-02, -1.91367196e-01, -2.26316015e-01, -2.07824067e-02,\n        -1.19455079e+00,  6.31552577e-01,  2.16968813e-01,  1.70381572e+00,\n         3.38975209e-01, -2.90454843e-01,  4.19816826e-01, -1.62796346e-01,\n        -5.54544819e-01,  3.49319893e-01, -3.65847998e-02,  2.64957938e-01,\n         4.16590378e-01, -1.00663959e+00, -1.80812434e-01, -3.75141842e-01,\n         4.48027070e-01, -6.98271496e-01,  6.35601048e-02, -8.38603271e-02,\n         2.35972550e-01, -1.46839649e-01, -1.32720837e-01, -1.55435119e-02,\n         1.52957568e-01, -1.12265868e-01,  2.63319737e-01,  3.74330255e-01,\n        -5.07303289e-01,  1.21805721e-01, -8.46797116e-02,  1.77169402e-01,\n         3.23355162e-01,  4.70337887e-01, -5.29570258e-01,  2.94205407e-01,\n         1.54275089e-01,  3.31007347e-01, -5.20088287e-01, -9.94734850e-01,\n         3.85159150e-01, -2.26536848e-01, -2.61480650e-01,  1.74612044e-01,\n        -3.67537176e-01, -3.15981619e-01, -4.66424064e-01,  4.28653325e-01,\n        -4.15262055e-01, -2.42297673e-01, -2.67096259e-01, -4.99541559e-01,\n        -9.43457852e-03, -7.29842488e-03, -2.43026673e-01,  8.17226186e-03,\n        -1.62114684e-01, -2.11178991e-01,  1.24390434e-01, -5.41309247e-02,\n        -8.62121731e-01, -4.95945096e-03,  3.76364816e-01, -1.62233787e-01,\n         1.79238331e-01, -9.87519315e-02, -5.91725684e-02, -1.44597760e-01,\n        -3.65417271e-01, -7.84946604e-02, -1.61688411e-01, -2.88281841e-01,\n        -9.56322443e-02,  3.78892246e-01,  5.48472468e-01, -1.80762979e-01,\n        -4.00510756e-01, -5.15408426e-01,  9.71356054e-02,  1.70680728e-01,\n         2.50839834e-01, -3.51454653e-01,  5.15888602e-01, -2.72576534e-01,\n        -1.39329984e-01,  8.16518318e-01, -2.19655817e-02,  5.99798260e-01,\n        -2.71479920e-01, -1.32057086e+00,  1.85978314e-01,  1.69292917e-02,\n         2.94022988e-01, -6.32391531e-01,  4.60984378e-01, -4.99635167e-02,\n        -8.65474200e-02, -2.43350063e-01,  5.87177829e-01,  3.66160863e-01,\n        -1.26372699e-01,  1.66648265e-01, -1.36046326e-01, -1.37693280e-01,\n         1.64893602e-02, -3.02629753e-01,  3.06901479e-01, -1.77202712e-01,\n         1.23184080e-01,  5.46095754e-01, -2.65125535e-01,  1.35723336e-01,\n        -5.38065723e-01,  7.00552059e-02,  2.36657069e-01,  2.36136222e-01,\n         8.02361600e-01,  3.06476748e-01, -7.14360599e-02,  2.38235170e-01,\n        -7.27540977e-02,  1.28506317e-03,  4.35799093e-01,  7.05174837e-01,\n        -3.39914442e-02,  1.17439416e+00,  9.72073838e-01,  2.95907606e-01,\n        -1.97497105e-01, -2.25529602e-01,  6.65821645e-02,  7.02737602e-01,\n         3.94994031e-02, -2.51736936e-02,  4.91379470e-01, -4.53844448e-01,\n         6.24801990e-01, -3.85648396e-01,  3.41982348e-01, -4.42133137e-01,\n         3.92587971e-01,  4.36927962e-01, -2.45698364e-01, -4.70058839e-01,\n        -1.29169956e-01,  7.67843941e-02, -1.07363073e-01, -3.14525096e-01,\n        -4.29918907e-01,  2.88960341e-01,  3.81081904e-01,  4.41421358e-02,\n        -3.65442094e-01,  3.13044830e-01, -2.26850028e-01,  2.95904988e-01,\n         4.76560899e-01,  2.19648888e-01, -8.06083071e-01, -1.76908746e-01,\n        -3.36366818e-01,  2.37791708e-01, -5.09905858e-01,  4.97619542e-01,\n         1.24838193e+00,  6.43125028e-01,  2.31643856e-01,  2.29033886e-01,\n        -2.38745304e-01, -3.93877621e-01, -5.46398456e-01, -1.58341627e-02,\n        -5.17429679e-02, -1.54266724e-01,  5.28967844e-01, -2.59654414e-01,\n         4.03990465e-01,  7.10969394e-01, -1.37364893e-01,  3.30588366e-01,\n        -1.06677494e+00, -1.04367868e+00,  4.37796497e-01, -5.55342168e-01,\n        -4.93636890e-01, -1.86194357e-01, -5.26819047e-02,  1.70578880e-01,\n        -4.49724473e-01,  6.89715296e-02,  3.41452204e-01,  3.43662359e-01,\n         2.15073557e-01, -4.79020798e-01,  1.55410666e-01,  1.69544088e-01,\n        -1.44725469e-01,  4.89396150e-01,  2.54681018e-01,  1.27411215e-02,\n        -2.35237126e-01, -1.45187514e-01,  5.38070634e-01,  6.21742158e-01,\n        -1.41730960e-01,  1.07284242e-01,  6.72286538e-01,  3.77970321e-01,\n         1.67351822e-01,  1.10223283e-01,  3.11003195e-01, -4.81290124e-01,\n         3.86666534e-01,  8.65557918e-02, -1.84754740e-01, -1.01556163e+00,\n         4.10636807e-01, -3.33536657e-01,  2.11547025e-01,  2.31053911e-01,\n        -2.29658484e-01,  2.66865888e-01,  1.09519230e+00, -3.79036731e-01,\n         7.45348917e-01, -4.63897671e-01,  3.52854563e-02, -1.37451915e-01,\n        -3.17477896e-01, -2.58748699e-01, -4.78984320e-01, -1.56700219e-01,\n         4.72974979e-02, -3.88361456e-01,  1.88624100e-02, -3.57468936e-01,\n        -1.55030564e-01, -7.18492065e-02,  8.20329258e-01, -6.15717222e-02,\n         1.05049282e-02, -2.81637388e-01,  4.23628096e-01,  9.63143108e-01,\n        -2.98908755e-01, -6.30584031e-01,  8.22334597e-02,  2.45741081e-01,\n        -8.09852453e-01,  5.79079852e-02,  4.73616953e-01,  3.57578182e-01,\n        -3.39324008e-01,  4.06473772e-02,  1.06225757e+00, -2.73305595e-01,\n         3.58240592e-01,  5.03883252e-01, -1.68678249e-02]),\n array([ 0.31518157, -0.28849561, -0.46447785, ..., -1.12149533,\n         0.01933702, -0.3659306 ]),\n array([[-0.01950505, -0.01950505, -0.01950505, ..., -0.01950505,\n         -0.01950505, -0.01950505],\n        [-0.01171342, -0.01171342, -0.01171342, ..., -0.01171342,\n         -0.01171342, -0.01171342],\n        [-0.00628569, -0.00628569, -0.00628569, ..., -0.00628569,\n         -0.00628569, -0.00628569],\n        ...,\n        [-0.00597366, -0.00597366, -0.00597366, ..., -0.00597366,\n         -0.00597366, -0.00597366],\n        [-0.00715661, -0.00715661, -0.00715661, ..., -0.00715661,\n         -0.00715661, -0.00715661],\n        [-0.00160694, -0.00160694, -0.00160694, ..., -0.00160694,\n         -0.00160694, -0.00160694]]),\n array([[-0.01036385, -0.01036385, -0.01036385, ..., -0.01036385,\n         -0.01036385, -0.01036385],\n        [-0.00201539, -0.00201539, -0.00201539, ..., -0.00201539,\n         -0.00201539, -0.00201539],\n        [ 0.00448636,  0.00448636,  0.00448636, ...,  0.00448636,\n          0.00448636,  0.00448636],\n        ...,\n        [-0.00500775, -0.00500775, -0.00500775, ..., -0.00500775,\n         -0.00500775, -0.00500775],\n        [-0.00493309, -0.00493309, -0.00493309, ..., -0.00493309,\n         -0.00493309, -0.00493309],\n        [-0.00498422, -0.00498422, -0.00498422, ..., -0.00498422,\n         -0.00498422, -0.00498422]]))"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rsvd = RegularizedSingularValueDecomposition(records_train, records_test)\n",
    "\n",
    "mu, b_u, b_i, U, V = rsvd.gradient_descent(100)\n",
    "ratings_predict_rsvd = performance(mu, b_u, b_i, U, V, records_test)\n",
    "\n",
    "\n",
    "nomu = Nomu(records_train, records_test)\n",
    "mu, b_u, b_i, U, V = nomu.gradient_descent(100)\n",
    "\n",
    "\n",
    "nobi = Nobi(records_train, records_test)\n",
    "\n",
    "nobi.gradient_descent(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "f = open(\"results.txt\", 'w')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "a = 5\n",
    "f.write(f\"{a}\")\n",
    "f.write('\\n')\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-6f5355759d99>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-4-6f5355759d99>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.017, 0.8058]\n",
      "GG\n",
      "0\n",
      "879\n",
      "[1.5149, 1.1714]\n",
      "1\n",
      "0\n",
      "[1.5149, 1.1715]\n",
      "2\n",
      "0\n",
      "[1.5149, 1.1715]\n",
      "3\n",
      "0\n",
      "[1.5149, 1.1716]\n",
      "4\n",
      "0\n",
      "[1.5149, 1.1716]\n",
      "5\n",
      "0\n",
      "[1.5156, 1.1722]\n",
      "6\n",
      "0\n",
      "[1.5159, 1.1728]\n",
      "7\n",
      "0\n",
      "[1.5163, 1.1733]\n",
      "8\n",
      "0\n",
      "[1.5163, 1.1733]\n",
      "9\n",
      "0\n",
      "[1.5161, 1.1731]\n",
      "10\n",
      "0\n",
      "[1.516, 1.1729]\n",
      "11\n",
      "0\n",
      "[1.516, 1.1729]\n",
      "12\n",
      "0\n",
      "[1.5153, 1.1722]\n",
      "13\n",
      "0\n",
      "[1.5154, 1.1724]\n",
      "14\n",
      "0\n",
      "[1.5154, 1.1724]\n",
      "15\n",
      "0\n",
      "[1.5157, 1.1727]\n",
      "16\n",
      "0\n",
      "[1.5157, 1.1727]\n",
      "17\n",
      "0\n",
      "[1.5158, 1.1728]\n",
      "18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-4-6f5355759d99>\u001B[0m in \u001B[0;36mgradient_descent\u001B[1;34m(self, n_iter)\u001B[0m\n\u001B[0;32m     85\u001B[0m                 \u001B[0mV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[0meta\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mgradient_V\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m                 \u001B[0mratings_predict_rsvd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mperformance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m                 \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mratings_predict_rsvd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m                     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m                     \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py\u001B[0m in \u001B[0;36m_amin\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     41\u001B[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001B[0;32m     42\u001B[0m           initial=_NoValue, where=True):\n\u001B[1;32m---> 43\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mumr_minimum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf = MatrixFactorization(records_train, records_test)\n",
    "\n",
    "mf.gradient_descent(70)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-8edc6e2cfb79>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-52-8edc6e2cfb79>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9617, 0.7601]\n",
      "[0.95, 0.7487]\n",
      "[0.9435, 0.7406]\n",
      "[0.943, 0.7392]\n",
      "[0.9426, 0.7391]\n",
      "[0.9432, 0.7394]\n",
      "[0.9432, 0.7388]\n",
      "[0.9429, 0.7385]\n",
      "[0.9435, 0.7389]\n",
      "[0.9438, 0.7388]\n",
      "[0.944, 0.739]\n",
      "[0.9445, 0.7392]\n",
      "[0.9445, 0.7391]\n",
      "[0.9443, 0.7389]\n",
      "[0.9446, 0.7392]\n",
      "[0.945, 0.7392]\n",
      "[0.945, 0.739]\n",
      "[0.9453, 0.7393]\n",
      "[0.9454, 0.7393]\n",
      "[0.9454, 0.7393]\n",
      "[0.9455, 0.7393]\n",
      "[0.9455, 0.7393]\n",
      "[0.9457, 0.7393]\n",
      "[0.9457, 0.7393]\n",
      "[0.9458, 0.7394]\n",
      "[0.9458, 0.7394]\n",
      "[0.9459, 0.7394]\n",
      "[0.9459, 0.7394]\n",
      "[0.9459, 0.7394]\n",
      "[0.9459, 0.7395]\n",
      "[0.946, 0.7395]\n",
      "[0.946, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9461, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-53-fc0f1f2ef030>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mnobi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNobi\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mnobi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient_descent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-52-8edc6e2cfb79>\u001B[0m in \u001B[0;36mgradient_descent\u001B[1;34m(self, n_iter)\u001B[0m\n\u001B[0;32m     70\u001B[0m                 \u001B[0muser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0musers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m                 \u001B[0mitem\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mitems\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m                 \u001B[0mgradient_mu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient_b_u\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient_b_i\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient_U\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient_V\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdJ_sgd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_u\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_i\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mU\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mR\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m                 \u001B[1;31m# mu -= eta * gradient_mu\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[1;31m# b_u[user] -= eta * gradient_b_u\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-52-8edc6e2cfb79>\u001B[0m in \u001B[0;36mdJ_sgd\u001B[1;34m(mu, b_u, b_i, U, V, r)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdJ_sgd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_u\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_i\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mU\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mV\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m             \u001B[0me\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mr\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mmu\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mb_u\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mb_i\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mU\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mV\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0me\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mb_u\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0me\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mb_i\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0me\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mV\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mU\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0me\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mU\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mV\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "f = open(\"results_nobi_2.txt\", 'w')\n",
    "nobi = Nobi(records_train, records_test)\n",
    "\n",
    "nobi.gradient_descent(100)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-a9fdcd92662e>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-49-a9fdcd92662e>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n",
      "<ipython-input-50-1b751bfdfbcb>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-50-1b751bfdfbcb>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.967, 0.7609]\n",
      "[1.0189, 0.7831]\n",
      "[0.9702, 0.7561]\n",
      "[0.9638, 0.7557]\n",
      "[0.9601, 0.7617]\n",
      "[0.9469, 0.7415]\n",
      "[0.9404, 0.7367]\n",
      "[0.9386, 0.734]\n",
      "[0.9389, 0.7326]\n",
      "[0.9361, 0.7297]\n",
      "[0.9339, 0.7327]\n",
      "[0.9357, 0.7279]\n",
      "[0.9359, 0.7391]\n",
      "[0.9326, 0.7281]\n",
      "[0.9319, 0.7312]\n",
      "[0.9312, 0.7308]\n",
      "[0.9314, 0.7291]\n",
      "[0.9373, 0.7273]\n",
      "[0.9327, 0.7274]\n",
      "[0.9317, 0.7276]\n",
      "[0.9389, 0.7276]\n",
      "[0.9319, 0.727]\n",
      "[0.9315, 0.7272]\n",
      "[0.931, 0.7305]\n",
      "[0.9359, 0.7268]\n",
      "[0.9311, 0.7314]\n",
      "[0.931, 0.727]\n",
      "[0.9323, 0.7266]\n",
      "[0.9318, 0.7267]\n",
      "[0.9305, 0.7288]\n",
      "[0.9305, 0.7285]\n",
      "[0.9306, 0.7278]\n",
      "[0.9306, 0.7298]\n",
      "[0.9307, 0.7274]\n",
      "[0.9306, 0.7297]\n",
      "[0.9306, 0.7298]\n",
      "[0.9305, 0.7287]\n",
      "[0.9306, 0.7294]\n",
      "[0.9309, 0.7273]\n",
      "[0.9308, 0.7275]\n",
      "[0.9307, 0.7277]\n",
      "[0.9307, 0.7275]\n",
      "[0.9308, 0.7274]\n",
      "[0.9306, 0.7277]\n",
      "[0.9306, 0.728]\n",
      "[0.9305, 0.7285]\n",
      "[0.9307, 0.7276]\n",
      "[0.9305, 0.7283]\n",
      "[0.9305, 0.7287]\n",
      "[0.9305, 0.7281]\n",
      "[0.9306, 0.7278]\n",
      "[0.9306, 0.7278]\n",
      "[0.9305, 0.7284]\n",
      "[0.9307, 0.7276]\n",
      "[0.9308, 0.7273]\n",
      "[0.9307, 0.7275]\n",
      "[0.9307, 0.7276]\n",
      "[0.9306, 0.7278]\n",
      "[0.9305, 0.7281]\n",
      "[0.9307, 0.7275]\n",
      "[0.9307, 0.7276]\n",
      "[0.9305, 0.7282]\n",
      "[0.9306, 0.7277]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.7281]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9306, 0.7279]\n",
      "[0.9305, 0.728]\n",
      "[0.9306, 0.7278]\n",
      "[0.9305, 0.728]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9305, 0.728]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "[0.9306, 0.7279]\n",
      "RSVD FINISHED\n",
      "[0.9711, 0.7649]\n",
      "[0.9668, 0.7589]\n",
      "[0.9664, 0.7615]\n",
      "[0.9617, 0.7558]\n",
      "[0.9517, 0.7472]\n",
      "[0.9444, 0.7416]\n",
      "[0.9398, 0.7371]\n",
      "[0.9393, 0.7349]\n",
      "[0.9343, 0.7318]\n",
      "[0.9364, 0.7318]\n",
      "[0.9347, 0.732]\n",
      "[0.9343, 0.7329]\n",
      "[0.9327, 0.7302]\n",
      "[0.9317, 0.7296]\n",
      "[0.9317, 0.7294]\n",
      "[0.9312, 0.729]\n",
      "[0.9311, 0.7285]\n",
      "[0.9312, 0.7288]\n",
      "[0.9308, 0.7281]\n",
      "[0.9309, 0.7285]\n",
      "[0.9308, 0.7281]\n",
      "[0.9308, 0.728]\n",
      "[0.931, 0.7283]\n",
      "[0.9308, 0.7282]\n",
      "[0.9307, 0.7281]\n",
      "[0.9306, 0.7279]\n",
      "[0.9308, 0.728]\n",
      "[0.9307, 0.7282]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.7281]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "[0.9307, 0.728]\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f = open(\"results_others.txt\", 'w')\n",
    "\n",
    "rsvd = RegularizedSingularValueDecomposition(records_train, records_test)\n",
    "\n",
    "mu, b_u, b_i, U, V = rsvd.gradient_descent(100)\n",
    "ratings_predict_rsvd = performance(mu, b_u, b_i, U, V, records_test)\n",
    "\n",
    "\n",
    "nomu = Nomu(records_train, records_test)\n",
    "mu, b_u, b_i, U, V = nomu.gradient_descent(100)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-4c5406b3ac98>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(self.R, axis=0) / y_item,\n",
      "<ipython-input-66-4c5406b3ac98>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.sum(y * (self.R - self.r_u.reshape(-1, 1)), axis=0) / y_item,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.962, 0.7604]\n",
      "[0.9615, 0.7599]\n",
      "[0.9569, 0.7554]\n",
      "[0.9463, 0.7443]\n",
      "[0.9428, 0.7404]\n",
      "[0.942, 0.7392]\n",
      "[0.9421, 0.7388]\n",
      "[0.9418, 0.7379]\n",
      "[0.9428, 0.7385]\n",
      "[0.9427, 0.7384]\n",
      "[0.9422, 0.7381]\n",
      "[0.9429, 0.7383]\n",
      "[0.9433, 0.7384]\n",
      "[0.9435, 0.7385]\n",
      "[0.9435, 0.7387]\n",
      "[0.9436, 0.7385]\n",
      "[0.9439, 0.7386]\n",
      "[0.9441, 0.7388]\n",
      "[0.9441, 0.7388]\n",
      "[0.9443, 0.7388]\n",
      "[0.9445, 0.7389]\n",
      "[0.9447, 0.7389]\n",
      "[0.9446, 0.7389]\n",
      "[0.9447, 0.7389]\n",
      "[0.9449, 0.739]\n",
      "[0.9452, 0.7391]\n",
      "[0.9453, 0.7392]\n",
      "[0.9454, 0.7392]\n",
      "[0.9453, 0.7392]\n",
      "[0.9453, 0.7391]\n",
      "[0.9455, 0.7392]\n",
      "[0.9455, 0.7393]\n",
      "[0.9457, 0.7393]\n",
      "[0.9457, 0.7393]\n",
      "[0.9457, 0.7393]\n",
      "[0.9457, 0.7393]\n",
      "[0.9458, 0.7393]\n",
      "[0.9459, 0.7394]\n",
      "[0.9459, 0.7394]\n",
      "[0.946, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9461, 0.7395]\n",
      "[0.9462, 0.7395]\n",
      "[0.9462, 0.7396]\n",
      "[0.9462, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9463, 0.7396]\n",
      "[0.9464, 0.7396]\n",
      "[0.9464, 0.7396]\n",
      "[0.9464, 0.7396]\n",
      "[0.9464, 0.7396]\n",
      "[0.9465, 0.7396]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9465, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9466, 0.7397]\n",
      "[0.9467, 0.7397]\n",
      "[0.9467, 0.7397]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9467, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "[0.9468, 0.7398]\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f = open(\"results_nobi_2.txt\", 'w')\n",
    "nobi = Nobi(records_train, records_test)\n",
    "\n",
    "nobi.gradient_descent(100)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}